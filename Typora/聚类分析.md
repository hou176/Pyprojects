- 一种典型的无监督学习算法，主要用于将相似的样本自动归到一个类别中。   分类和聚类最大的区别就是分类是有监督  而聚类是无监督
- 聚类算法的常用在现实中
	- 用户画像  广告推荐  data segmentation  搜索引擎的流量推荐  恶意流量识别
	- 基于位置信息的商业推送  新闻聚类  筛选排序
	- 图像分割  降维 识别  离群点测试 信用卡异常消费  发掘相同功能的基因片段
- 聚类的API  sklearn.cluster.KMeans(n_clusters=8)
	- 参数:
		- n_clusters:开始的聚类中心数量 整型，缺省值=8，生成的聚类数，即产生的质心（centroids）数
	- 方法
		- estimator.fit(x)
		- estimator.predict(x)
		- estimator.fit_predict(x)
			- 计算聚类中心并预测每个样本属于哪个类别,相当于先调用fit(x),然后再调用predict(x)
- k-means的聚类步骤  一个一个找点   然后验证点是不是自己需要的那个点  算出每一个点中心的距离  然后每个点定下来后附近开始附着  下面的步骤就是这样
	1、随机设置K个特征空间内的点作为初始的聚类中心
	2、对于其他每个点计算到K个中心的距离，未知的点选择最近的一个聚类中心点作为标记类别
	3、接着对着标记的聚类中心之后，重新计算出每个聚类的新中心点（平均值）
	4、如果计算得出的新中心点与原中心点一样（质心不再移动），那么结束，否则重新进行第二步过程
- kmeans模型的评估  
	- 误差平方和（SSE）
	- 轮廓系数
	- 肘方法  用来确定K值得选择
	- CH系数
- 优点：
	1.原理简单（靠近中心点），实现容易
	​2.聚类效果中上（依赖K的选择）
	​3.空间复杂度o(N)，时间复杂度o(IKN)
- 缺点
	1.对离群点，噪声敏感 （中心点易偏移）
	​2.很难发现大小差别很大的簇及进行增量计算
	3.结果不一定是全局最优，只能保证局部最优（与K的个数及初值选取有关）
- kemeans是可以优化的   比如用kmeans++  二分kmeans  kernel kmeans  等等