1- 欧式距离
	- 就是一个三角形经典的二次方的问题
	- 根号下  A1方  -  A2方
- 曼哈顿距离
	- 相当一个二维的欧式距离   他们的计算方式是一样的  维度变多而已
- 切比雪夫距离也是很像前两者  本体意义差不多 (x1,y1) (x2,y2)  前者减去后者的关系
- 闵式距离 是一个含义性的东西  分别代表着前三个  p=1  就是曼哈顿  p=2时候就是欧式   有着开平方  p=无限大   就是切比雪夫的距离了   
	- 将各个分量的量纲(scale也就是“单位”相同的看待了; 
	- 未考虑各个分量的分布（期望，方差等）可能是不同的。
-  汉明距离  是针对字符串的  其中一个变成另外一个的最小字符替换次数
	- 汉明重量是字符串相当于同样长度的零字符串的汉明距离  也就是字符串中非0的个数  二进制中的1   汉明重量分析的意义是信息论 编码理论  密码学等领域都有应用  比如信息编码的过程  增加容错性  汉明距离尽可能的大一点

- 跟聚类差不多   K值小了受影响  过大影响样本均衡 
	- 近似误差 
		- 对训练集的训练误差 关注训练集
		- 近似误差  会过拟合  对现在有的有好预测  但是未知的有着较大的偏差  
		- 模型本事不是最佳模型
	- 估计误差
		- 关注测试集  
		- 对未知的预测能力好  
		- 本身是最优模型
	- 预测误差减小，估计误差就会变大，K值的减小就意味着整体模型变得复杂，容易发生过拟合； 
	- 估计误差变小，但是近似误差会变大，输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且K值的增大就意味着整体的模型变得简单。
	- 在实际应用中K值一般取一个比较小的数值   交叉验证选择最优的K值
- K值小受异常点影响，过拟合  K值大均衡问题，欠拟合