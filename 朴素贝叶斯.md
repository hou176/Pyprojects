- 朴素贝叶斯一般都是用来分类的  文本分类  比如垃圾邮件分类  文章分类
  - 使用后验概率进行对文本的判断
  - 
- 概率基础
	- 概率定义为一件事情发生的可能性
	- 联合概率包含多个条件  且所有条件都成立的概率  P（A,B）特点 P(A)P(B)
	- 条件概率  事情A在事情B已经发生条件下的发生概率P(A|B)特点P(A1,A2|B) = P(A1|B)(A2|B) 这个概率的实现是由于A1A2相互独立的结果 
- 其实朴素贝叶斯常用在文章分类上
公式分为三个部分：
	- P(C)：每个文档类别的概率(某文档类别数／总文档数量)
	- P(W│C)：给定类别下特征（被预测文档中出现的词）的概率
		- 计算方法：P(F1│C)=Ni/N （训练文档中去计算）
		- Ni为该F1词在C类别所有文档中出现的次数
		- N为所属类别C下的文档所有词出现的次数和
	- P(F1,F2,…) 预测文档中每个词的概率
- 拉普拉斯平滑系数  防止计算概率是0 
- API  sklearn.naive_bayes.MultinomialNB(alpha = 1.0)
	- 朴素贝叶斯分类
 	- alpha：拉普拉斯平滑系数
fit_transform和transform
	 	-fit_transform()的作用就是先拟合数据，然后转化它将其转化为标准形式。
 	- 即tranform()的作用是通过找中心和缩放等实现标准化。  
 	- 结果是一样的  但是不能互换  transform函数是一定可以替换为fit_transform函数的，fit_transform函数不能替换为transform函数！



先验概率

- 她出门的概率

似然概率

- 出门没带钥匙的概率

后验概率

- 没带钥匙出门的概率

p(AB) = p(BA) = p(A|B)p(B)




